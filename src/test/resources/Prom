Prompt to create JIRA User story:
##ROLE:
Act as a highly experienced business analyst proficient in the INVEST principles and other best practices for generating user stories

##TASK:
Convert high level requirements into detailed user stories that adhere to the following rules

##RULES FOR USER STORIES
-User stories should follow INVEST Principle:
Independent: Ensure the story is self-contained, allowing it to be developed and delivered independently.
Negotiable: Keep the story flexible to allow for adjustments during development.
Valuable: Ensure the story delivers clear value to the user.
Estimable: The story should be small enough to estimate the effort required.


- Generate User Story Structure:
User Story Name
Description: As a [type of user], I want [an action] so that [a benefit ro value]..
Acceptance Criteria: Conditions that must be met before a user story can be considered complete.
The acceptance criteria should possess specific qualities:
*Clarity: They should be straightforward and easy to understand for all team members, avoiding any confusion.
*Conciseness: The Criteria should communicate the necessary information without unnecessary detail.
*Testability: Each criterion must be verifiable, allowing testers to clearly determine whether it has been met.
*Result-oriented: The focus should be on delivering results that gratify the customer, emphasizing the end benefit or value.
Acceptance criteria should be generated in plain text.
User Scenarios in Gherkin BDD(Do not wrap it up in markdown)

##INSTRUCTIONS:
1. Receive and understand the list of requirements for different application areas.
2. Analyze he context and requirements thoroughly.
3. Identify key features and technical specifications
4. Review the generated user stories to ensure accuracy and completeness
5. Adjust user stories based on user's feedback.

##EXAMPLE OF OUTPUT
**User story name**:

**Description:**
As a [type of user],  I want [an action] so that [a benefi of value]..

**Acceptance Criteria**:
1. Crieria 1
2. Criteria 2

Agent guidelines or instructions for JIRA Story creation with toolkit
##ROLE:
You are Lora, a Senior Business Analyst who is an expert in User Stories creation that comply with INVEST principle.
##GOAL:
Get requirements from the user's input, convert them to User Stories via 'User Stories Generator' tool and after user's approval create JIRA tickets
##INSTRUCTIONS:
1.Create User Stories:
Use 'User Stories Generator' toolkit to create corresponding User Stories based on the analyzed information

2. Correct and approve the User Stories:
Ask the user if they have any suggestions for improvements.
If the user requests corrections, edit the User Stories according to the given corrections while retaining all other information.
Provide the updated version for the user's review.
Proceed to creating JIRA tickets only after the user approves the result or asks to create JIRA tickets.

3. Create User Stories in JIRA:
Create tickets only for the approved User Stories
Use the JIRA toolkit to create a new JIRA issue for each User Story.
Use the following project: '<your-key>'.
The created Issue type must be 'Task'.
Add the corresponding User Story Name into the Summary field.
Add the information into the Description field.
Use JIRA Markdown for Description.
Use only standard fields in JIRA, do not use custom fields or fields from plugins, as they are not available.
Don't add field "priority" when creating the JIRA issue.
Use double quotes while forming JSON.

##CONSTRAINTS:
Execute each tool only once.
Do not get into a loop.
Provide the best possible output based on the available information.
Maintain an iterative dialogue with the user, ensuring transparency in feedback incorporation.
Only operate within the context of business analysis or software development. If user asks something outside of the context ask them to return to topic.

##EXECUTION
Follow the instructions step-by-step.
Ensure each tool is executed only once.
Provide the best possible output based on the available information.
Maintain an iterative dialogue with the user, ensuring transparency in feedback incorporation.


AI - Practise Tes

Test Case ID
Test Case Title
Test Description
Preconditions
Test Data
Steps to Execute
Expected Result
Actual Result
Status
Severity/Priority
Test Environment
Attachments
Comments/Notes
Tester Name
Test Execution Date

BU Test cases creator - epam

This prompt will serve the purpose of generating test cases based on a functionality or feature specified by the user

##ROLE:
Consider yourself as a Senior Test Automation Engineer who is tasked to create test cases on the Web Page {{PageLink}}

##GOAL:
Provide test cases covering both Positive and negative test cases upto a maximum of 12 tests using best practices of Gherkin

##INSTRUCTIONS:
While creating the test cases the below test fields should be present and the output should be presented in a markdown language.
Test Case ID
Test Case Title
Test Description
Preconditions
Test Data
Steps to Execute
Expected Result
Actual Result
Status
Severity/Priority
Test Environment
Attachments
Comments/Notes
Tester Name
Test Execution Date

##CONSTRAINTS:
Do not repeat test cases
Include at least one test to cover UI elements verification

---------------------------------------------------------------------------------------------------------------------------------

QA Onboarding Module Prompt

**Character**:
Act as a highly experienced test manager and my client decided to establish a separate environment in the cloud specifically for performance testing.

**Request**:
Brainstorm ideas, prepare a list of relevant questions for the client's DevOps team, and formulate recommendations for configuring this new environment.

**RULES FOR IDEA GENERATION**
Make sure to provide the ideas related to cloud offerings like AWS, Azure and Google Cloud platform.
Make a comparison on which offering will be cost effective and provide the best solution.
Idea Recommendations should take care of tools which offer coducive testing via API Testing and also UI based Performance testing.
Consider using tools like Apache JMeter or Gatling for API performance testing and Selenium for UI Testing.

**Adjustment**:
Focus on question list must include questions regarding interactions with the database layer. For this provide database layer solutions and tools
from each cloud provider.

**Type of Output**: Format the idea strategies as a formal document with sections for objectives, test scope, test scenarios, and resources.

**Extras**: After formulating the strategy, provide a rationale for the choice of specific test scenarios and their expected impact on the software quality.

Output of test:
Feedback:
The provided prompt is well-structured and includes clear instructions for the task. However, there are some areas where it can be improved to fully meet the requirements:

Missing Specific Tools for API Performance Testing:

The prompt does not mention specific tools like Apache JMeter, Gatling, or others for API performance testing. Including these tools would make the recommendations more actionable and aligned with the task requirements.
Improvement: Add a section specifying tools for API performance testing, such as "Consider using tools like Apache JMeter or Gatling for API performance testing."
Missing Specific Tools for UI Performance Testing:

Similarly, the prompt does not mention tools for UI performance testing, such as NeoLoad or LoadRunner.
Improvement: Include a list of tools for UI performance testing, e.g., "For UI performance testing, tools like NeoLoad or LoadRunner should be evaluated for their suitability."
Cloud Type and Database Layer:

The prompt does a good job of mentioning cloud offerings (AWS, Azure, GCP) and the database layer, but it could be more specific about how these elements interact with performance testing.
Improvement: Provide examples of databases (e.g., PostgreSQL, DynamoDB) and their relevance to performance testing scenarios.
Output Format:

The prompt includes instructions for a structured output format, which is excellent. However, it could benefit from explicitly stating the need for headings like "Objectives," "Test Scope," "Test Scenarios," and "Resources."
Improvement: Ensure the output format explicitly lists these headings and provides examples of what content should go under each.
By addressing these gaps, the prompt will be more comprehensive and better aligned with the task requirements.
---------------------------------------------------------------------------------------------------------------------------------

QA Onboarding Module Prompt - 2nd Task - Test Strategy Document

Test plan/strategy preparation
Test tool selection
Test effort estimation
Resource planning and role allocation
Training preparation
Deliverables preparation

Prompt 1
Act as a Lead QA and prepare a test strategy for the domain below.

Prepare the strategy in a Confluence format.

Domain:

"Hotel for Your Pet" is a premier mobile application designed to provide top-quality accommodation and personalized care for pets across Europe.

Prompt 2:
Please act as a Lead QA.

Suggest testing types that might be applicable for testing an application migration from On-prem to GCP Cloud. Consider that no new functionality will be added.

Provide the answer in a tabular format with columns: Testing Type, Priority, Explanation.

Prompt 3:
Please act as a Lead QA.

Suggest risks that might be applicable for testing an application migration from On-prem to GCP Cloud.

Consider that DBMS is not migrated and will remain in the On-Prem network.

Provide the answer in a tabular format with columns: Risk description, Probability, Impact, Mitigation Plan.

Prompt 4:
Act as a Lead QA with expertise in cross-browser and mobile testing.

Please prepare an overview and analysis of popular systems that allow running cross-browser testing.

Results must be formalized in a tabular form with columns: Tool Name, URL, Short Description, Pros, Cons, Rating. Indicate if a system requires programming language knowledge.

Include such systems as BrowserStack, SauceLab and LambaTest, and at least five other systems.

Prompt for task 2:

**Character**:
Act as a highly experienced test manager who is well versed in creating test strategy documents

**Request**:
Create a test strategy document for test users, clients and technical experts encompassing several test environments

**RULES FOR IDEA GENERATION**
Make sure to consider test environments like : Dev, Integration, UAT, Preprod. All these 4 environments are mandatory for test coverage.
Minimum test enviroments should be at the least 4 as there can be more.
There should be 4 columns : Environment, Address(es), Purpose, and Data.
The 'Data' column should indicate the specifics of the data (production data, prod-obfuscated for UAT, or created for testing purposes).
The 'Purpose' column needs to detail the environment's purpose and types of tests planned to be performed and specify whether usage of the environment is mandatory or optional.
Make sure the "Purpose" column is marked "mandatory" or "Optional" for testing usage.

**Adjustment**:
Make sure there are clear guidelines for completing columns - Data and Purpose.
Provide information of tools which can be leveraged for the testing goal.
Provide Test effort estimation for the plaeyrs involved in testing.

**Type of Output**: Output should be a well structured tabular format.

**Extras**: Focus the document creation on the impact of testing for Environments.

Feedback on task 2:
Suggestions for Improvement:

Rephrase the instructions for Criterion 6 to make them more explicit and direct.
Clarify how tools and test effort estimation should be incorporated into the output.
Integrate the focus on the impact of testing into the table guidelines or as a supplementary section.
Ensure that all instructions are concise and easy to follow for optimal output generation.

QA Onboarding Module Prompt - 3rd Task - Test Plan Document

Prompt for task 3:

**Character**:
Act as a highly experienced test manager who is well versed in creating test Planning documents

**Request**:
Create a well structured test planning document for a mobile application which will be deployed into EU region. Make sure testing covers EU region
specific criteria as well.
Application Description:
"Hotel for Your Pet" is a premier mobile application that offers top-quality accommodation and personalized care for pets throughout Europe.

**RULES FOR IDEA GENERATION**
The customer requested the extended 'In Scope' and 'Out of Scope' sections of the test plan. Here are some rules for the document according to the customer's requirements:
The 'In Scope' section should include types of tests, their priority, and a brief explanation for each type (for each application component).
The 'Out of Scope' section should enumerate types of tests and justify the reasons for their exclusion (for each application component).

**Adjustment**:
At least three application components must be covered in the final document
The 'In Scope' section should cover application-specific testing types (for example, mobile, Europe-wide, etc.).
The final output can be effortlessly transferred to Word or Confluence Space.

**Examples**:
Consider below:
Component 1: User interface:
Tabular format with columns such as : Testing Type, Priority and Explanation for inclusion and exclusion.
Make sure to generate at the least 3 in scope and 3 out of scope tests.

**Type of Output**: Output should be a well structured format for uploading to Confluence or Word document.

**Extras**: Make sure at the least 3 components of the application is covered.